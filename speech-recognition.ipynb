{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10813256,"sourceType":"datasetVersion","datasetId":6712945}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"82274084-0b66-4459-87e2-a625e29d1ae2","_cell_guid":"a9862d86-1599-4422-a690-55d78267bdda","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-25T13:02:45.370108Z","iopub.execute_input":"2025-02-25T13:02:45.370407Z","iopub.status.idle":"2025-02-25T13:02:46.592197Z","shell.execute_reply.started":"2025-02-25T13:02:45.370379Z","shell.execute_reply":"2025-02-25T13:02:46.591076Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install librosa pydub speechrecognition --quiet","metadata":{"_uuid":"ea91e51e-8dd0-403d-9370-c1eacfbf2a43","_cell_guid":"94a45a97-5a31-4bcb-aabf-41a843493e4a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-25T13:02:46.593026Z","iopub.execute_input":"2025-02-25T13:02:46.593508Z","iopub.status.idle":"2025-02-25T13:02:52.062630Z","shell.execute_reply.started":"2025-02-25T13:02:46.593477Z","shell.execute_reply":"2025-02-25T13:02:52.061628Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport librosa\nimport speech_recognition as sr\nfrom pydub import AudioSegment\nimport logging\nimport shutil\nimport IPython\nfrom IPython import display as ipd","metadata":{"_uuid":"9abffa45-53eb-4828-9640-9025419b563a","_cell_guid":"75c7ea06-7374-4a6c-b0bb-568762fe4344","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-25T13:02:52.063577Z","iopub.execute_input":"2025-02-25T13:02:52.063802Z","iopub.status.idle":"2025-02-25T13:02:52.130363Z","shell.execute_reply.started":"2025-02-25T13:02:52.063776Z","shell.execute_reply":"2025-02-25T13:02:52.129500Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"Creating the audio files from the dataset: DAIC-WOZ\"\"\"\n\ndata_dir = '/kaggle/input/daic-woz'\n\naudio_dir = '/kaggle/working/audio_files'\nos.makedirs(audio_dir, exist_ok = True)\n\nfolders = [entry.name for entry in os.scandir(data_dir) if entry.is_dir()]\naudio_files = []\n\nfor folder in folders:\n    folder = os.path.join(data_dir, folder)\n\n    audio_file = [entry.name for entry in os.scandir(folder) if os.path.splitext(entry.name)[1] == '.wav']\n    audio_file = os.path.join(folder, audio_file[0])\n    audio_files.append(audio_file)\n    if os.path.exists(audio_file):\n        shutil.copy(audio_file, os.path.join(audio_dir, os.path.basename(audio_file)))\n        print(\"Sucessfully Moved\")\n    else:\n        print(\"Some Error Occured\")","metadata":{"_uuid":"55b2fdc2-caf5-43c4-97af-72e2b875750d","_cell_guid":"704bc4e2-279e-4e70-bc10-8386903bd9e5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-25T13:02:52.131290Z","iopub.execute_input":"2025-02-25T13:02:52.131772Z","iopub.status.idle":"2025-02-25T13:02:54.536260Z","shell.execute_reply.started":"2025-02-25T13:02:52.131751Z","shell.execute_reply":"2025-02-25T13:02:54.535520Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRANSCRIPT_DIR = \"/kaggle/working/transcripts\"\nos.makedirs(TRANSCRIPT_DIR, exist_ok=True)","metadata":{"_uuid":"99207e11-6d4c-4116-8df5-14f2a4960bf7","_cell_guid":"2499a509-a412-4435-8884-0c61e2c8e9bb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-25T13:02:54.538006Z","iopub.execute_input":"2025-02-25T13:02:54.538260Z","iopub.status.idle":"2025-02-25T13:02:54.541877Z","shell.execute_reply.started":"2025-02-25T13:02:54.538240Z","shell.execute_reply":"2025-02-25T13:02:54.540944Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Using Speech Recognition System to get the speech to text\naudio_dir = '/kaggle/working/audio_files'\nTRANSCRIPT_DIR = \"/kaggle/working/transcripts\"\nclass SpeechToText:\n    def __init__(self, audio_dir=audio_dir, transcript_dir=TRANSCRIPT_DIR):\n        \"\"\"Initialize the SpeechToText converter.\"\"\"\n        self.recognizer = sr.Recognizer()\n        self.audio_dir = audio_dir\n        self.transcript_dir = transcript_dir\n    \n    def convert_file(self, audio_file_path, api=\"google\"):\n        \"\"\"Convert a single audio file to text.\"\"\"\n\n        try:\n            # Check if file is WAV format, convert if not\n            if not audio_file_path.lower().endswith('.wav'):\n                audio_file_path = self._convert_to_wav(audio_file_path)\n                print(\"I am here\")\n            \n            with sr.AudioFile(audio_file_path) as source:\n                audio_data = self.recognizer.record(source)\n                \n                if api == \"google\":\n                    print(\"I am here in google.\")\n                    text = self.recognizer.recognize_google(audio_data)\n                elif api == \"sphinx\":\n                    text = self.recognizer.recognize_sphinx(audio_data)\n                else:\n                    print(\"API Not Supported\")\n                    return None\n                    \n                print(f\"Transcription successful: {text[:50]}...\")\n                return text\n                \n        except Exception as e:\n            return None\n    \n    def _convert_to_wav(self, audio_file_path):\n        \"\"\"Convert audio file to WAV format.\"\"\"\n        try:\n            file_name = os.path.basename(audio_file_path)\n            name, _ = os.path.splitext(file_name)\n            wav_path = os.path.join(self.audio_dir, f\"{name}.wav\")\n            \n            audio = AudioSegment.from_file(audio_file_path)\n            audio = audio.set_channels(1)  # Convert to mono\n            audio = audio.set_frame_rate(16000)  # Set sample rate to 16kHz\n            audio.export(wav_path, format=\"wav\")\n            \n           \n            return wav_path\n        except Exception as e:\n            raise\n    \n    def process_directory(self, api=\"google\"):\n        \"\"\"Process all audio files in the audio directory.\"\"\"\n        transcripts = {}\n        \n        for filename in os.listdir(self.audio_dir):\n            if filename.endswith(('.wav', '.mp3', '.flac', '.ogg')):\n                filepath = os.path.join(self.audio_dir, filename)\n                print(\"Processing\", filepath)\n                \n                # Get transcript\n                transcript = self.convert_file(filepath)\n                \n                if transcript:\n                    # Save transcript to file\n                    name, _ = os.path.splitext(filename)\n                    transcript_path = os.path.join(self.transcript_dir, f\"{name}.txt\")\n                    \n                    with open(transcript_path, 'w') as f:\n                        f.write(transcript)\n                    \n                    transcripts[name] = transcript\n        \n        return transcripts","metadata":{"_uuid":"4cbd4fc4-724a-4e1c-86a0-8c9cd83f0149","_cell_guid":"115eb219-76f3-4387-a139-77be3210e384","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-25T13:02:54.543037Z","iopub.execute_input":"2025-02-25T13:02:54.543286Z","iopub.status.idle":"2025-02-25T13:02:54.557804Z","shell.execute_reply.started":"2025-02-25T13:02:54.543257Z","shell.execute_reply":"2025-02-25T13:02:54.556980Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stt = SpeechToText()\ntranscripts = stt.process_directory(audio_dir)\nprint(transcripts)","metadata":{"_uuid":"91f97d1a-1ffc-4cdc-a142-b233cb3ecf37","_cell_guid":"ccf3c697-5bc0-4aa8-9a41-a767ae94c5de","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-25T13:05:16.820082Z","iopub.execute_input":"2025-02-25T13:05:16.820365Z","iopub.status.idle":"2025-02-25T13:20:33.112330Z","shell.execute_reply.started":"2025-02-25T13:05:16.820344Z","shell.execute_reply":"2025-02-25T13:20:33.111510Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"d3d9a9af-65af-466c-98aa-9cc43a70363b","_cell_guid":"ecab0e87-ec14-4aa9-b9b6-a2d67f5b7d1d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}